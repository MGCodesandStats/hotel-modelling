{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise SparkSession and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "conf.set('spark.local.dir', 'path')\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonbq import pythonbq\n",
    "\n",
    "myProject=pythonbq(\n",
    "  bq_key_path='json_file',\n",
    "  project_id='project_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>MarketSegment</th>\n",
       "      <th>ArrivalDateMonth</th>\n",
       "      <th>DepositType</th>\n",
       "      <th>CustomerType</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>ArrivalDateYear</th>\n",
       "      <th>ArrivalDateWeekNumber</th>\n",
       "      <th>ArrivalDateDayOfMonth</th>\n",
       "      <th>RequiredCarParkingSpaces</th>\n",
       "      <th>IsCanceled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "      <td>July</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>July</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>88</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>July</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>65</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>July</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>92</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>July</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29991</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>June</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>Transient</td>\n",
       "      <td>178</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>June</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>Transient</td>\n",
       "      <td>178</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>June</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>Transient</td>\n",
       "      <td>178</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>June</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>Transient</td>\n",
       "      <td>178</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>FRA</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>June</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>Transient</td>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29996 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country  MarketSegment ArrivalDateMonth      DepositType CustomerType  \\\n",
       "0         PRT  Offline TA/TO             July  No Deposit         Transient   \n",
       "1         PRT      Online TA             July  No Deposit         Transient   \n",
       "2         PRT      Online TA             July  No Deposit         Transient   \n",
       "3         PRT      Online TA             July  No Deposit         Transient   \n",
       "4         PRT      Online TA             July  No Deposit         Transient   \n",
       "...       ...            ...              ...              ...          ...   \n",
       "29991     PRT         Groups             June  Non Refund         Transient   \n",
       "29992     PRT         Groups             June  Non Refund         Transient   \n",
       "29993     PRT         Groups             June  Non Refund         Transient   \n",
       "29994     PRT         Groups             June  Non Refund         Transient   \n",
       "29995     FRA      Online TA             June  No Deposit         Transient   \n",
       "\n",
       "       LeadTime  ArrivalDateYear  ArrivalDateWeekNumber  \\\n",
       "0             6             2015                     27   \n",
       "1            88             2015                     27   \n",
       "2            65             2015                     27   \n",
       "3            92             2015                     27   \n",
       "4           100             2015                     27   \n",
       "...         ...              ...                    ...   \n",
       "29991       178             2017                     23   \n",
       "29992       178             2017                     23   \n",
       "29993       178             2017                     23   \n",
       "29994       178             2017                     23   \n",
       "29995        31             2017                     23   \n",
       "\n",
       "       ArrivalDateDayOfMonth  RequiredCarParkingSpaces  IsCanceled  \n",
       "0                          1                         0           0  \n",
       "1                          1                         0           1  \n",
       "2                          1                         0           1  \n",
       "3                          1                         0           1  \n",
       "4                          2                         0           1  \n",
       "...                      ...                       ...         ...  \n",
       "29991                      9                         0           1  \n",
       "29992                      9                         0           1  \n",
       "29993                      9                         0           1  \n",
       "29994                      9                         0           1  \n",
       "29995                      9                         0           1  \n",
       "\n",
       "[29996 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_CODE=\"\"\"\n",
    "SELECT Country, MarketSegment, ArrivalDateMonth, DepositType, CustomerType, LeadTime, ArrivalDateYear, ArrivalDateWeekNumber, ArrivalDateDayOfMonth, RequiredCarParkingSpaces, IsCanceled FROM `table.H2data`\n",
    "\"\"\"\n",
    "output=myProject.query(sql=SQL_CODE)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "import pyarrow\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "dataset = sqlContext.createDataFrame(output)\n",
    "\n",
    "# If reading from CSV:\n",
    "# dataset= spark.read.load(\"H2full.csv\", format=\"csv\", header=\"true\", inferSchema=True)\n",
    "\n",
    "dataset\n",
    "cols = dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa\n",
    "# https://docs.databricks.com/applications/machine-learning/mllib/binary-classification-mllib-pipelines.html\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = [\"Country\", \"MarketSegment\", \"ArrivalDateMonth\", \"DepositType\", \"CustomerType\"]\n",
    "\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert label into label indices using the StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol=\"IsCanceled\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform all features into a vector using VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [\"LeadTime\", \"ArrivalDateYear\", \"ArrivalDateWeekNumber\", \"ArrivalDateDayOfMonth\", \"RequiredCarParkingSpaces\"]\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "  \n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(dataset)\n",
    "preppedDataDF = pipelineModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtClassifier = GBTClassifier()\n",
    "trainedModel = gbtClassifier.fit(preppedDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = preppedDataDF.select(selectedcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24002\n",
      "5994\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed=100)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtModel = gbtClassifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804772438666579"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9804772438666579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double, probability: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.toPandas().to_csv('h2predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.9314425575701684,0.06855744242983164]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8090487269487285,0.19095127305127146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8090487269487285,0.19095127305127146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8090487269487285,0.19095127305127146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8090487269487285,0.19095127305127146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>5989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.04929192444983682,0.9507080755501631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>5990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.05568750145988222,0.9443124985401178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>5991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.04689273875807077,0.9531072612419292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>5992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.11509902109403011,0.8849009789059699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>5993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.11849197966197092,0.8815080203380291]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5994 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  label  prediction                               probability\n",
       "0              0    0.0         0.0  [0.9314425575701684,0.06855744242983164]\n",
       "1              1    0.0         0.0  [0.8090487269487285,0.19095127305127146]\n",
       "2              2    0.0         0.0  [0.8090487269487285,0.19095127305127146]\n",
       "3              3    0.0         0.0  [0.8090487269487285,0.19095127305127146]\n",
       "4              4    0.0         0.0  [0.8090487269487285,0.19095127305127146]\n",
       "...          ...    ...         ...                                       ...\n",
       "5989        5989    1.0         1.0  [0.04929192444983682,0.9507080755501631]\n",
       "5990        5990    1.0         1.0  [0.05568750145988222,0.9443124985401178]\n",
       "5991        5991    1.0         1.0  [0.04689273875807077,0.9531072612419292]\n",
       "5992        5992    1.0         1.0  [0.11509902109403011,0.8849009789059699]\n",
       "5993        5993    1.0         1.0  [0.11849197966197092,0.8815080203380291]\n",
       "\n",
       "[5994 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata=pd.read_csv(\"h2predictions.csv\")\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=mydata['label']\n",
    "prediction=mydata['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4701  157]\n",
      " [ 236  900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96      4858\n",
      "         1.0       0.85      0.79      0.82      1136\n",
      "\n",
      "    accuracy                           0.93      5994\n",
      "   macro avg       0.90      0.88      0.89      5994\n",
      "weighted avg       0.93      0.93      0.93      5994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label,prediction))\n",
    "print(classification_report(label,prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
